{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "output_dataset = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function, derivate\n",
    "sigm = lambda x : 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmoid = (\n",
    "    lambda x : sigm(x),\n",
    "    lambda x : sigm(x) * (1 - sigm(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function, derivate\n",
    "mean_square_error = (\n",
    "    lambda predictions, targets : np.mean((predictions - targets) ** 2),\n",
    "    lambda predictions, targets : predictions - targets\n",
    ")\n",
    "\n",
    "def bin_cross_entropy(predictions, targets):\n",
    "    return -np.mean(targets * np.log(predictions) + (1 - targets) * np.log(1 - predictions))\n",
    "\n",
    "cross_entropy = (\n",
    "    lambda predictions, targets : bin_cross_entropy(predictions, targets),\n",
    "    lambda predictions, targets : predictions - targets\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralLayer:\n",
    "    def __init__(self, num_connections_entering, num_neurons, activation_fn):\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "        # create from -1 to 1\n",
    "        self.bias = np.random.rand(1, num_neurons) * 2 - 1\n",
    "        self.weights = np.random.rand(num_connections_entering, num_neurons) * 2 - 1\n",
    "        \n",
    "        self.num_connections_entering = num_connections_entering\n",
    "        self.num_neurons = num_neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "def create_neural_network():\n",
    "    neuralNetwork = [\n",
    "        NeuralLayer(num_connections_entering=2, num_neurons=4, activation_fn=sigmoid),\n",
    "        NeuralLayer(num_connections_entering=4, num_neurons=1, activation_fn=sigmoid),\n",
    "    ]\n",
    "    \n",
    "    return neuralNetwork\n",
    "    \n",
    "XOR = create_neural_network()\n",
    "\n",
    "def print_neural_network(neuralNetwork):\n",
    "    list_indexes = list(range(neuralNetwork[0].num_connections_entering))\n",
    "    inputs_names = list(map(lambda i: f\"input {i + 1}\", list_indexes))\n",
    "    \n",
    "    print(inputs_names, end=\"\\n\\n\")\n",
    "    \n",
    "    for i, layer in enumerate(neuralNetwork):\n",
    "        print(f\"layer {i}: {layer.bias.shape[1]} neurons\")\n",
    "        print(\"weights\")\n",
    "        print(layer.weights, end=\"\\n\\n\")\n",
    "        print(\"bias\")\n",
    "        print(layer.bias, end=\"\\n\\n\")\n",
    "        \n",
    "print_neural_network(XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foward_pass(neural_network, inputs, print_it=True):\n",
    "    input_to_layer = inputs\n",
    "    steps = [(None, inputs)]\n",
    "    \n",
    "    for _, layer in enumerate(neural_network):\n",
    "        ponderate_sum = input_to_layer @ layer.weights + layer.bias\n",
    "        input_to_layer = activation = layer.activation_fn[0](ponderate_sum)\n",
    "        \n",
    "        steps.append((ponderate_sum, activation))\n",
    "    \n",
    "    if print_it:\n",
    "        prediction = np.hstack((inputs, input_to_layer))\n",
    "        print(\"Current behavior\")\n",
    "        print(prediction, end=\"\\n\\n\")\n",
    "    \n",
    "    return steps\n",
    "\n",
    "steps = foward_pass(XOR, input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(neural_network, inputs, outputs, cost_function, show, learning_rate = 3.2):\n",
    "    steps = foward_pass(neural_network, inputs, show)\n",
    "    deltas = [None] * len(neural_network)\n",
    "    \n",
    "    next_layer_weights = None\n",
    "    num_layers, num_inputs = len(neural_network), inputs.shape[0]\n",
    "\n",
    "    for i in reversed(range(num_layers)):\n",
    "        ponderate_sum, activation = steps[i + 1]\n",
    "        _, activation_last_layer = steps[i]\n",
    "        \n",
    "        if i == num_layers - 1:\n",
    "            cost_activation = cost_function[1](activation, outputs)\n",
    "        else:\n",
    "            cost_activation = deltas[i + 1] @ next_layer_weights.T / num_inputs\n",
    "            \n",
    "        activation_ponderate = neural_network[i].activation_fn[1](ponderate_sum)\n",
    "        deltas[i] = delta = cost_activation * activation_ponderate\n",
    "        \n",
    "        gradient_weights = (activation_last_layer.T @ delta) / num_inputs\n",
    "        gradient_bias = np.mean(delta, axis=0, keepdims=True)\n",
    "        \n",
    "        next_layer_weights = neural_network[i].weights\n",
    "        \n",
    "        neural_network[i].bias -= learning_rate * gradient_bias\n",
    "        neural_network[i].weights -= learning_rate * gradient_weights\n",
    "        \n",
    "    error = cost_function[0](steps[-1][1], outputs)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_step(neural_network, input_dataset, output_dataset, cost_function, show):\n",
    "    error_before = backpropagation(neural_network, input_dataset, output_dataset, cost_function, show)\n",
    "    print(f\"current error = {error_before}\")\n",
    "    \n",
    "    if show: \n",
    "        steps = foward_pass(neural_network, input_dataset, False)\n",
    "        error_after = cost_function[0](steps[-1][1], output_dataset)\n",
    "        \n",
    "        print_neural_network(neural_network)\n",
    "        \n",
    "        print(f\"new error = {error_after}\")\n",
    "        print(f\"difference = {abs(error_before - error_after)}\", end=\"\\n\\n\")\n",
    "        \n",
    "    return error_before\n",
    "        \n",
    "x = show_step(XOR, input_dataset, output_dataset, cross_entropy, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(times = (200, 4500))\n",
    "def trainXOR(times):\n",
    "    global errors\n",
    "    for i in range(times):\n",
    "        error = show_step(XOR, input_dataset, output_dataset, cross_entropy, False)\n",
    "        errors.append(error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = foward_pass(XOR, input_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
